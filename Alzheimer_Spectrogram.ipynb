{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FtM1997/Alzheimer-s-disease-Paper/blob/main/Alzheimer_Spectrogram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQPNR08rglpt"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<h1>Reach Spectrogram images for input of NN<h1>\n",
        "Amin Abdipour</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load data"
      ],
      "metadata": {
        "id": "b73M9cBvTNU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiKIbhdXTH26",
        "outputId": "9ab868de-a024-4da8-a4d4-0d25a3cc38ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "import os"
      ],
      "metadata": {
        "id": "kYM4vIh7Jivd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = os.path.join('/content/drive/My Drive/','Alzheimer','EEG_full_4D_1Hz.mat')  # Path to the Data folder"
      ],
      "metadata": {
        "id": "n3DHoImFKgM0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = scipy.io.loadmat(dir)\n",
        "eeg_data = data['EEG']"
      ],
      "metadata": {
        "id": "ZL0jry0gJWGC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eeg_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J39iZ4LSJcIV",
        "outputId": "9f489d2c-531a-4a0c-a7d6-3728d9e3034a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65, 2500, 19, 74)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num=data['epoch_num']"
      ],
      "metadata": {
        "id": "B64xuXO-L0F9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F3VXlGuL4eT",
        "outputId": "7a601f76-7543-4ed1-c41d-85f2d238de89"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Spectrogram"
      ],
      "metadata": {
        "id": "6NJTjhlVwdYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define sampling rate and parameters for spectrogram\n",
        "sampling_rate = 250\n",
        "window = 'hann'\n",
        "nperseg = 128\n",
        "noverlap = 64\n",
        "nfft = 128\n",
        "\n",
        "# Frequency range of interest (1 to 40 Hz)\n",
        "freq_range = (1, 45)\n",
        "\n",
        "# Calculate number of 10-second segments\n",
        "segment_duration = 10  # in seconds\n",
        "\n",
        "# Define lobes\n",
        "lobes = {\n",
        "    'Pre-frontal': [1, 2],\n",
        "    'Frontal': [3, 4, 11, 12, 17],\n",
        "    'Temporal': [13, 14, 15, 16],\n",
        "    'Parietal': [7, 8, 19],\n",
        "    'Central': [5, 6, 18],\n",
        "    'Occipital': [9, 10]\n",
        "}"
      ],
      "metadata": {
        "id": "zQPsZ59ktvTN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Spectrograms :)"
      ],
      "metadata": {
        "id": "8hptLxLGUoyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjects_of_interest = [29]\n",
        "# Iterate over each subject's data\n",
        "for subject_idx in subjects_of_interest:\n",
        "    subject_data = eeg_data[subject_idx, :, :,:]  # EEG data for the current subject\n",
        "\n",
        "    # Create directory to save spectrogram images\n",
        "    save_dir = os.path.join('/content/drive/My Drive/','Alzheimer','Spectrogram Images')\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # Iterate over each channel\n",
        "    for channel_idx in range(subject_data.shape[1]):\n",
        "        channel_data = subject_data[:,channel_idx, :]  # EEG data for the current channel\n",
        "\n",
        "        # Iterate over each 10-second segment\n",
        "        for seg_idx in range(epoch_num[0,subject_idx]):\n",
        "\n",
        "            segment_data = channel_data[:,seg_idx]      # EEG data for the current Segment\n",
        "\n",
        "            # Compute spectrogram\n",
        "            frequencies, times, spectrogram = signal.spectrogram(\n",
        "                segment_data, fs=sampling_rate, window=window, nperseg=nperseg,\n",
        "                noverlap=noverlap, nfft=nfft\n",
        "            )\n",
        "\n",
        "            # Plot spectrogram\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            plt.pcolormesh(times, frequencies, 10 * np.log10(spectrogram),\n",
        "                           shading='gouraud', cmap='viridis', vmin=-50, vmax=50)  # Adjust vmin and vmax as needed\n",
        "            plt.title(f'Spectrogram for Subject {subject_idx + 1}, Channel {channel_idx + 1}, Segment {seg_idx + 1}')\n",
        "            plt.xlabel('Time (seconds)')\n",
        "            plt.ylabel('Frequency (Hz)')\n",
        "            plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
        "\n",
        "            # Limit y-axis to frequency range of interest\n",
        "            plt.ylim(freq_range)\n",
        "\n",
        "            # Save all spectrogram image\n",
        "            save_path = os.path.join('/content/drive/My Drive/','Alzheimer','Spectrogram Images', 'All images',f'subject{subject_idx + 1}')\n",
        "            if not os.path.exists(save_path):\n",
        "                os.makedirs(save_path)\n",
        "            save_path2 = os.path.join(save_path, f'subject{subject_idx + 1}_channel{channel_idx + 1}_segment{seg_idx + 1}_spectrogram.png')\n",
        "            plt.savefig(save_path2)\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "\n",
        "            # Save spectrogram image for each lobe\n",
        "            for lobe_name, lobe_channels in lobes.items():\n",
        "                if channel_idx + 1 in lobe_channels:\n",
        "                    save_dir = os.path.join('/content/drive/My Drive/', 'Alzheimer', 'Spectrogram Images', lobe_name,f'subject{subject_idx + 1}')\n",
        "                    if not os.path.exists(save_dir):\n",
        "                        os.makedirs(save_dir)\n",
        "                    save_path = os.path.join(save_dir, f'subject{subject_idx + 1}_channel{channel_idx + 1}_segment{seg_idx + 1}_spectrogram.png')\n",
        "\n",
        "                    # Plot spectrogram\n",
        "                    plt.figure(figsize=(8, 6))\n",
        "                    plt.pcolormesh(times, frequencies, 10 * np.log10(spectrogram),\n",
        "                                  shading='gouraud', cmap='viridis', vmin=-50, vmax=50)  # Adjust vmin and vmax as needed\n",
        "                    plt.title(f'Spectrogram for Subject {subject_idx + 1}, Channel {channel_idx + 1}, Segment {seg_idx + 1}')\n",
        "                    plt.xlabel('Time (seconds)')\n",
        "                    plt.ylabel('Frequency (Hz)')\n",
        "                    plt.colorbar(label='Power/Frequency (dB/Hz)')\n",
        "\n",
        "                    # Limit y-axis to frequency range of interest\n",
        "                    plt.ylim(freq_range)\n",
        "                    plt.savefig(save_path)\n",
        "                    plt.close()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Spectrogram images saved successfully.\")"
      ],
      "metadata": {
        "id": "FyO_3L3kwTHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f98440f-4a7e-4e6b-b510-cfdd995daefd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram images saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. imCoh Connectivity"
      ],
      "metadata": {
        "id": "TMMIfm6PhjRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We2p7BOpheZQ",
        "outputId": "b8b58aea-b819-42f3-f280-2adf783d042f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/7.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/7.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/7.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/7.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/7.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/7.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/7.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m6.6/7.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from mne) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (24.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.8.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mne) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.0->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "# Load EEG data from .mat file using h5py\n",
        "# mat_file_path = 'EEG_data.mat'\n",
        "with h5py.File(dir, 'r') as file:\n",
        "    try:\n",
        "        eeg_class_dataset = file['EEG_Class']\n",
        "        print(\"Dataset Info:\")\n",
        "        print(\"Dataset Type:\", type(eeg_class_dataset))\n",
        "        print(\"Dataset Shape:\", eeg_class_dataset.shape)\n",
        "        print(\"Dataset dtype:\", eeg_class_dataset.dtype)\n",
        "        print(\"Dataset Value:\", eeg_class_dataset[:10])  # Print a slice of dataset values\n",
        "    except ValueError as e:\n",
        "        print(\"Error accessing dataset:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2QuTaEzj460",
        "outputId": "3ed81697-dc6f-488a-9581-334312f97a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "Dataset Type: <class 'h5py._hl.dataset.Dataset'>\n",
            "Dataset Shape: (88, 1)\n",
            "Dataset dtype: object\n",
            "Dataset Value: [[<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]\n",
            " [<HDF5 object reference>]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Load EEG data from .mat file using h5py\n",
        "# mat_file_path = 'EEG_data.mat'\n",
        "with h5py.File(dir, 'r') as file:\n",
        "    eeg_class_dataset = file['EEG_Class']\n",
        "    eeg_data = []\n",
        "\n",
        "    # Iterate over each object reference in the dataset\n",
        "    for ref in eeg_class_dataset[:]:\n",
        "        # Access the referenced object and load its data\n",
        "        subject_data = file[ref[0]][:]  # Assuming the reference is a single element list\n",
        "        eeg_data.append(subject_data)\n",
        "\n",
        "# Now 'eeg_data' contains the actual EEG data for each subject\n",
        "print(\"Number of subjects:\", len(eeg_data))\n",
        "print(\"Shape of the first subject's data:\", eeg_data[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9v8r235ktvS",
        "outputId": "fbcb9fe0-3b7f-4fbc-e4be-4080a746477d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of subjects: 88\n",
            "Shape of the first subject's data: (59, 19, 2500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "\n",
        "# Iterate over each subject's data\n",
        "for subject_idx, subject_data in enumerate(eeg_data):\n",
        "    # Process the EEG data for the subject (similar to the previous code)\n",
        "    # Create a list to store coherence plots for each subject\n",
        "    coherence_plots = []\n",
        "\n",
        "    # Iterate over each epoch in the subject's data\n",
        "    for epoch_idx, epoch_ref in enumerate(subject_data):\n",
        "        # Extract actual epoch data from reference object\n",
        "        epoch_data = file[epoch_ref[0]][:]\n",
        "\n",
        "        # Convert epoch data to MNE Raw object\n",
        "        info = mne.create_info(ch_names=['Channel {}'.format(i) for i in range(epoch_data.shape[1])],\n",
        "                               sfreq=100,  # Assuming 100 Hz sampling frequency\n",
        "                               ch_types='eeg')\n",
        "        raw = mne.io.RawArray(epoch_data.T, info)\n",
        "\n",
        "        # Compute coherence\n",
        "        fmin = 1  # Minimum frequency for coherence computation\n",
        "        fmax = 30  # Maximum frequency for coherence computation\n",
        "        coherence, freqs, times, n_epochs, n_tapers = mne.connectivity.spectral_connectivity(\n",
        "            raw, method='coh', mode='multitaper', fmin=fmin, fmax=fmax, faverage=True)\n",
        "\n",
        "        # Append coherence plot to list\n",
        "        coherence_plots.append(coherence)\n",
        "\n",
        "    # Concatenate coherence plots along the epoch axis\n",
        "    coherence_plots = np.concatenate(coherence_plots, axis=-1)\n",
        "\n",
        "    # Plot and save coherence images for each subject\n",
        "    for i in range(coherence_plots.shape[0]):\n",
        "        # Create MNE Info object for plotting\n",
        "        info = mne.create_info(ch_names=['Channel {}'.format(i) for i in range(coherence_plots.shape[1])],\n",
        "                               sfreq=100,  # Assuming 100 Hz sampling frequency\n",
        "                               ch_types='eeg')\n",
        "        fig, ax = mne.viz.plot_connectivity_topomap(coherence_plots[i], info, show=False)\n",
        "\n",
        "        # Save coherence images\n",
        "        save_dir = 'coherence_images'\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        fig.savefig(os.path.join(save_dir, 'subject{}_coherence_epoch{}.png'.format(subject_idx, i)))\n",
        "        plt.close(fig)"
      ],
      "metadata": {
        "id": "jdekgggoZ4HB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a95698-bbd1-4ff0-e6b8-993a0b90b723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 469, in shape\n",
            "    shape = self.id.shape\n",
            "  File \"h5py/h5d.pyx\", line 193, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/h5d.pyx\", line 194, in h5py.h5d.DatasetID.shape.__get__\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5d.pyx\", line 350, in h5py.h5d.DatasetID.get_space\n",
            "ValueError: Invalid dataset identifier (invalid dataset identifier)\n"
          ]
        }
      ]
    }
  ]
}