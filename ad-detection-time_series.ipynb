{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8995492,"sourceType":"datasetVersion","datasetId":5418300}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from scipy.io import loadmat\n# Zero Padded Data\n# data = loadmat(\"/content/drive/MyDrive/EEG_full_4D_1Hz.mat\")\n# Read data in Kaggle version \ndata = loadmat(\"/kaggle/input/eeg-dataset/EEG_full_4D_1Hz.mat\")\nprint(\"done\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-16T09:00:52.064749Z","iopub.execute_input":"2024-09-16T09:00:52.065136Z","iopub.status.idle":"2024-09-16T09:01:06.324290Z","shell.execute_reply.started":"2024-09-16T09:00:52.065097Z","shell.execute_reply":"2024-09-16T09:01:06.323409Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"epoch_num = data['epoch_num']\nepoch_num","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:03:20.923470Z","iopub.execute_input":"2024-09-16T09:03:20.924218Z","iopub.status.idle":"2024-09-16T09:03:20.931950Z","shell.execute_reply.started":"2024-09-16T09:03:20.924180Z","shell.execute_reply":"2024-09-16T09:03:20.931025Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"array([[46, 58, 27, 21, 36, 47, 48, 20, 41, 73, 36, 20, 48, 16, 74, 46,\n        44, 45, 33, 30, 57, 19, 48, 50, 19, 19, 37, 67, 29, 30, 59, 57,\n        29, 57, 22, 66, 38, 29, 48, 31, 35, 62, 44, 73, 26, 51, 23, 28,\n        65, 13, 30, 43, 34, 50, 46, 61, 34, 50, 42, 29, 16, 34, 48, 59,\n        29, 16, 30, 26, 47, 19, 45, 12, 52, 25, 35, 41, 29, 37, 35, 42,\n        39, 24, 18,  3, 24,  4, 27, 49]], dtype=uint8)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Inspect the EEG_Class structure\neeg_data = data['EEG']\neeg_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:03:22.680035Z","iopub.execute_input":"2024-09-16T09:03:22.680653Z","iopub.status.idle":"2024-09-16T09:03:22.686695Z","shell.execute_reply.started":"2024-09-16T09:03:22.680614Z","shell.execute_reply":"2024-09-16T09:03:22.685872Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(65, 2500, 19, 74)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Divide Data","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom PIL import Image\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential, Model, clone_model\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.layers import Conv2D, Input, ConvLSTM2D,MaxPooling3D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D, MaxPool2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.applications import VGG16, VGG19, ResNet50, InceptionV3, DenseNet121, EfficientNetB2\nfrom tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Input\nfrom tensorflow.keras.models import load_model\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nimport shutil\nimport scipy","metadata":{"execution":{"iopub.status.busy":"2024-09-16T09:03:24.605393Z","iopub.execute_input":"2024-09-16T09:03:24.605836Z","iopub.status.idle":"2024-09-16T09:03:37.746556Z","shell.execute_reply.started":"2024-09-16T09:03:24.605775Z","shell.execute_reply":"2024-09-16T09:03:37.745516Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"lobes = {\n    'Frontal': [1, 2, 3, 4, 11, 12, 17],\n    'Temporal': [13, 14, 15, 16],\n    'Parietal': [7, 8, 19],\n    'Central': [5, 6, 18],\n    'Occipital': [9, 10]\n}\n\n\n######################### KAGGLE VERSION ###############################\n\nimport os\n# Iterate over each subject's data\nfor subject_idx in range(eeg_data.shape[0]):\n    subject_data = eeg_data[subject_idx, :, :,:]  # EEG data for the current subject\n\n    # Create directory to save time-series\n    save_dir = os.path.join('/kaggle/working/','Alzheimer','Time_series')\n    if not os.path.exists(save_dir):\n        os.makedirs(save_dir)\n\n    # Iterate over each channel\n    # channels_of_interest = [6,7, 12,13]\n\n    #for channel_idx in channels_of_interest:\n    for channel_idx in range(subject_data.shape[1]):\n        channel_data = subject_data[:,channel_idx, :]  # EEG data for the current channel\n\n        # Iterate over each 10-second segment\n        # for seg_idx in range(epoch_num[0,subject_idx]):\n        for seg_idx in range(10):\n\n            segment_data = channel_data[:,seg_idx]      # EEG data for the current Segment\n\n            # Save all time-series\n            save_path = os.path.join(save_dir, 'All lobes',f'subject{subject_idx + 1}')\n            if not os.path.exists(save_path):\n                os.makedirs(save_path)\n            save_path2 = os.path.join(save_path, f'subject{subject_idx + 1}_channel{channel_idx + 1}_segment{seg_idx + 1}')\n            np.save(save_path2,segment_data)\n\n\n\n            # Save spectrogram image for each lobe\n            for lobe_name, lobe_channels in lobes.items():\n                if channel_idx + 1 in lobe_channels:\n                    save_dir2 = os.path.join('/kaggle/working/', 'Alzheimer', 'Time_series', lobe_name,f'subject{subject_idx + 1}')\n                    if not os.path.exists(save_dir2):\n                        os.makedirs(save_dir2)\n                    save_path = os.path.join(save_dir2, f'subject{subject_idx + 1}_channel{channel_idx + 1}_segment{seg_idx + 1}')\n\n                    np.save(save_path, segment_data)\n\n\nprint(\"saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:03:52.477160Z","iopub.execute_input":"2024-09-16T10:03:52.477891Z","iopub.status.idle":"2024-09-16T10:03:59.669290Z","shell.execute_reply.started":"2024-09-16T10:03:52.477849Z","shell.execute_reply":"2024-09-16T10:03:59.668380Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"saved successfully.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Augmentation ","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# from scipy.interpolate import interp1d\n\n# def standardize_length(signal, target_length=2500):\n#     current_length = len(signal)\n#     if current_length < target_length:\n#         # Pad the signal if it is shorter than the target length\n#         padding = np.zeros(target_length - current_length)\n#         signal = np.concatenate((signal, padding))\n#     elif current_length > target_length:\n#         # Trim the signal if it is longer than the target length\n#         signal = signal[:target_length]\n#     return signal\n\n\n# def load_eeg_data(file_path):\n#     # Assuming the EEG data is stored in a NumPy binary file (.npy). Adjust this as necessary.\n#     return np.load(file_path)\n\n\n# def time_reverse(signal, probability=0.5):\n#     if np.random.rand() < probability:\n#         return signal[::-1]\n#     return signal\n\n\n# def smooth_time_mask(signal, mask_length, probability=0.5):\n#     if np.random.rand() < probability:\n#         if mask_length < len(signal):\n#             start = np.random.randint(0, len(signal) - mask_length)\n#             signal[start:start + mask_length] = 0\n#         else:\n#             # Handle case where mask length is inappropriate\n#             print(\"Mask length is too long for the signal size.\")\n#     return signal\n\n\n\n# def gaussian_noise(signal, sigma=0.05, probability=0.5):\n#     if np.random.rand() < probability:\n#         noise = np.random.normal(0, sigma, size=len(signal))\n#         return signal + noise\n#     return signal\n\n\n\n\n# def channel_dropout(signal, dropout_prob=0.1):\n#     if signal.ndim == 2:  # Multi-channel data\n#         num_channels = signal.shape[1]\n#         if np.random.rand() < dropout_prob and num_channels > 1:\n#             channels_to_drop = np.random.choice(num_channels, size=np.random.randint(1, num_channels), replace=False)\n#             signal[:, channels_to_drop] = 0\n#     return signal\n\n\n# def time_warp(signal, time_warping_prob=0.5):\n#     if np.random.rand() < time_warping_prob:\n#         length = len(signal)\n#         original_indices = np.arange(length)\n#         warp_points = np.sort(np.random.choice(original_indices[1:-1], size=2, replace=False))\n#         warp_factors = np.random.uniform(0.5, 1.5, size=2)\n        \n#         new_indices = np.concatenate([\n#             np.linspace(0, warp_points[0], num=int(warp_factors[0] * warp_points[0]), endpoint=False),\n#             np.linspace(warp_points[0], warp_points[1], num=int(warp_factors[1] * (warp_points[1] - warp_points[0])), endpoint=False),\n#             np.linspace(warp_points[1], length, num=int((length - warp_points[1]) * warp_factors[1]))\n#         ])\n        \n#         new_indices = np.clip(new_indices, 0, length-1)\n#         new_indices = np.round(new_indices).astype(int)\n        \n#         if signal.ndim == 1:  # Single-channel\n#             interpolation_function = interp1d(original_indices, signal, kind='linear', fill_value='extrapolate')\n#             signal = interpolation_function(original_indices)\n#         else:  # Multi-channel\n#             for i in range(signal.shape[1]):\n#                 interpolation_function = interp1d(original_indices, signal[:, i], kind='linear', fill_value='extrapolate')\n#                 signal[:, i] = interpolation_function(original_indices)\n        \n#     return signal\n\n\n\n\n\n# def amplitude_scaling(signal, scaling_prob=0.5, min_scale=0.8, max_scale=1.2):\n#     if np.random.rand() < scaling_prob:\n#         scale_factor = np.random.uniform(min_scale, max_scale)\n#         signal = signal * scale_factor\n#     return signal\n\n\n# # def augment_eeg_signal(signal, mask_length=50, noise_sigma=0.05, time_rev_prob=0.5, mask_prob=0.5, noise_prob=0.5):\n# #     signal = load_eeg_data(file_path)  # Load data\n# #     # Apply TimeReverse\n# #     signal = time_reverse(signal, probability=time_rev_prob)\n\n# #     # Apply SmoothTimeMask\n# #     signal = smooth_time_mask(signal, mask_length=mask_length, probability=mask_prob)\n\n# #     # Apply GaussianNoise\n# #     signal = gaussian_noise(signal, sigma=noise_sigma, probability=noise_prob)\n\n# #     return signal\n\n\n# def augment_eeg_signal(signal_path, mask_length=50, noise_sigma=0.05, time_rev_prob=0.5, mask_prob=0.5, noise_prob=0.5, target_length=2500):\n#     signal = load_eeg_data(signal_path)  # Load data\n#     #print(\"Original:\", signal.shape)\n#     signal = standardize_length(signal, target_length=target_length)\n#     #print(\"After Length Standardization:\", signal.shape)\n#     signal = time_reverse(signal, probability=time_rev_prob)\n#     #print(\"After Time Reverse:\", signal.shape)\n\n#     signal = smooth_time_mask(signal, mask_length=mask_length, probability=mask_prob)\n#     #print(\"After Smooth Time Mask:\", signal.shape)\n\n#     signal = gaussian_noise(signal, sigma=noise_sigma, probability=noise_prob)\n#     #print(\"After Gaussian Noise:\", signal.shape)\n\n#     signal = amplitude_scaling(signal)\n#     #print(\"After Amplitude Scaling:\", signal.shape)\n\n#     signal = channel_dropout(signal)\n#     #print(\"After Channel Dropout:\", signal.shape)\n\n#     signal = time_warp(signal, time_warping_prob=0.5)\n#     #print(\"After Time Warp:\", signal.shape)\n\n#     # Standardize the length of the signal to ensure consistency\n    \n\n#     return signal\n\n\n\n\n\n\n# import os \n# data_dir = \"/kaggle/working/Alzheimer/Time_series/All lobes\"\n# folders = os.listdir(data_dir)\n# for folder in folders:\n#   address = os.path.join(data_dir, folder)\n#   particular_subject_folder = os.listdir(address)\n#   for file in particular_subject_folder:\n#     if file.endswith(\".npy\"):\n#         file_path = os.path.join(address, file)\n#         sig = augment_eeg_signal(file_path)\n#         save_path = os.path.join(address, \"Augmented_\" + file)\n#         np.save(save_path, sig)\n# print(\"Data Augmentation completed Success fully\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:10:36.953363Z","iopub.execute_input":"2024-09-14T07:10:36.954019Z","iopub.status.idle":"2024-09-14T07:10:40.402105Z","shell.execute_reply.started":"2024-09-14T07:10:36.953978Z","shell.execute_reply":"2024-09-14T07:10:40.401176Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Data Augmentation completed Success fully\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Entering","metadata":{}},{"cell_type":"code","source":"# Run this for Colab\n# data_dir = \"/content/Alzheimer/Time_series/Temporal\"\n# Run this for Kaggle\ndata_dir = \"/kaggle/working/Alzheimer/Time_series/Parietal\"\n\ndef extract_numeric_part(folder_name):\n    parts = folder_name.split('_')\n    for part in parts:\n        if part.startswith('subject'):\n            return int(part.replace('subject', ''))\n    return -1  # Return -1 if no numeric part is found\n\nfolders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))], key=extract_numeric_part)\n\nsubject_folders, labels = [], []\n\nfor folder_name in folders:\n    subject_num = extract_numeric_part(folder_name)\n    subject_folder = os.path.join(data_dir, folder_name)\n    subject_folders.append(subject_folder)\n\n    if subject_num <= 36:\n        labels.append(0)  # AD group\n    elif 37 <= subject_num <= 65:\n        labels.append(1)  # HC group\n\nsubject_folders = np.array(subject_folders)\nlabels = np.array(labels)\n\nprint(\"Subject Folders:\", subject_folders)\nprint(\"Labels:\", labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:04:07.525328Z","iopub.execute_input":"2024-09-16T10:04:07.526035Z","iopub.status.idle":"2024-09-16T10:04:07.537769Z","shell.execute_reply.started":"2024-09-16T10:04:07.525998Z","shell.execute_reply":"2024-09-16T10:04:07.536765Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Subject Folders: ['/kaggle/working/Alzheimer/Time_series/Parietal/subject1'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject2'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject3'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject4'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject5'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject6'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject7'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject8'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject9'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject10'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject11'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject12'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject13'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject14'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject15'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject16'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject17'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject18'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject19'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject20'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject21'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject22'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject23'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject24'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject25'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject26'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject27'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject28'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject29'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject30'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject31'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject32'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject33'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject34'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject35'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject36'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject37'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject38'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject39'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject40'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject41'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject42'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject43'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject44'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject45'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject46'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject47'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject48'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject49'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject50'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject51'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject52'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject53'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject54'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject55'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject56'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject57'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject58'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject59'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject60'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject61'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject62'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject63'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject64'\n '/kaggle/working/Alzheimer/Time_series/Parietal/subject65']\nLabels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"def load_series_and_labels(subjects, labels):\n    series, labels_t = [], []\n    for subject_folder, label in zip(subjects, labels):\n        for filename in os.listdir(subject_folder):\n            series_path = os.path.join(subject_folder, filename.decode())\n            try:\n                ser = np.load(series_path)\n\n\n                series.append(ser)\n                labels_t.append(label)\n            except Exception as e:\n                print(f\"Error loading time-series: {series_path}, {e}\")\n\n    return np.array(series), np.array(labels_t)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:04:10.196366Z","iopub.execute_input":"2024-09-16T10:04:10.196721Z","iopub.status.idle":"2024-09-16T10:04:10.203657Z","shell.execute_reply.started":"2024-09-16T10:04:10.196688Z","shell.execute_reply":"2024-09-16T10:04:10.202632Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def load_and_preprocess_data(subject_folders, labels):\n    # Create dictionaries to categorize subjects into train, val, and test groups\n    train_subjects_dict = {}\n    val_subjects_dict = {}\n    test_subjects_dict = {}\n\n    for subject_folder, label in zip(subject_folders, labels):\n        subject_num = extract_numeric_part(os.path.basename(subject_folder))\n        if 33 <= subject_num <= 41 :\n            val_subjects_dict[subject_folder] = label\n        elif 27 <= subject_num  <= 32 or 42 <= subject_num <= 48:\n            test_subjects_dict[subject_folder] = label\n        else:\n            train_subjects_dict[subject_folder] = label\n\n    # Extract subjects and labels for each group\n    train_subjects = list(train_subjects_dict.keys())\n    train_labels = [train_subjects_dict[subj] for subj in train_subjects]\n    val_subjects = list(val_subjects_dict.keys())\n    val_labels = [val_subjects_dict[subj] for subj in val_subjects]\n    test_subjects = list(test_subjects_dict.keys())\n    test_labels = [test_subjects_dict[subj] for subj in test_subjects]\n\n    # Load images for each group\n    train_images, train_labels_t = load_series_and_labels(train_subjects, train_labels)\n    val_images, val_labels_t = load_series_and_labels(val_subjects, val_labels)\n    test_images, test_labels_t = load_series_and_labels(test_subjects, test_labels)\n    test_image_counts_per_subject = [len(os.listdir(folder)) for folder in test_subjects]\n\n    return train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:04:13.166411Z","iopub.execute_input":"2024-09-16T10:04:13.167126Z","iopub.status.idle":"2024-09-16T10:04:13.176340Z","shell.execute_reply.started":"2024-09-16T10:04:13.167078Z","shell.execute_reply":"2024-09-16T10:04:13.175477Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# ResNet","metadata":{}},{"cell_type":"code","source":"train_series, train_labels_t, val_series, val_labels_t, test_series, test_labels_t, test_subjects, test_image_counts_per_subject = load_and_preprocess_data(subject_folders, labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:04:16.241325Z","iopub.execute_input":"2024-09-16T10:04:16.242049Z","iopub.status.idle":"2024-09-16T10:04:16.812140Z","shell.execute_reply.started":"2024-09-16T10:04:16.242006Z","shell.execute_reply":"2024-09-16T10:04:16.811383Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.initializers import HeNormal\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, Add, GlobalAveragePooling1D, Dense, Dropout, Multiply, Reshape\n\ndef se_block(input_tensor, reduction_ratio=8):\n    \"\"\"Squeeze-and-Excitation block to add attention.\"\"\"\n    filters = input_tensor.shape[-1]\n    se_shape = (1, filters)\n    \n    # Squeeze operation\n    se = GlobalAveragePooling1D()(input_tensor)\n    se = Reshape(se_shape)(se)\n    \n    # Excitation operation\n    se = Dense(filters // reduction_ratio, activation='relu', use_bias=False)(se)\n    se = Dense(filters, activation='sigmoid', use_bias=False)(se)\n    \n    # Scaling the input_tensor with the learned attention\n    x = Multiply()([input_tensor, se])\n    return x\n\ndef residual_block(x, filters, kernel_size=3, stride=1, dilation_rate=1):\n    \"\"\"A residual block with SE block and dilated convolution for attention.\"\"\"\n    shortcut = x\n    \n    # First convolution with dilation\n    x = Conv1D(filters, kernel_size=kernel_size, strides=stride, padding='same', dilation_rate=dilation_rate, kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    x = ReLU()(x)\n    \n    # Second convolution with dilation\n    x = Conv1D(filters, kernel_size=kernel_size, strides=1, padding='same', dilation_rate=dilation_rate, kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    # new layer\n    #x = LSTM(64, return_sequences=True)(x)\n    #x = LSTM(64, return_sequences=True)(x)\n    #x = LSTM(64, return_sequences=True)(x)\n    # new layer\n    \n    # Adding the shortcut to the output of the convolutions\n    if x.shape[-1] != shortcut.shape[-1] or stride != 1:\n        shortcut = Conv1D(filters, kernel_size=1, strides=stride, padding='same', kernel_initializer='he_normal')(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n        \n    x = Add()([x, shortcut])\n    x = ReLU()(x)\n    \n    # Apply SE block (attention mechanism)\n    x = se_block(x)\n    \n    return x\n\ndef build_resnet(input_shape, num_classes):\n    inputs = Input(shape=input_shape)\n    \n    # Initial convolution\n    x = Conv1D(64, kernel_size=3, strides=1, padding='same', kernel_initializer=HeNormal())(inputs)\n    x = BatchNormalization()(x)\n    x = Dropout(0.7)(x)\n    x = ReLU()(x)\n    \n    # Adding residual blocks with attention\n    x = residual_block(x, 64, stride=1, dilation_rate=1)\n    x = residual_block(x, 128, stride=1, dilation_rate=2)\n    x = residual_block(x, 256, stride=1, dilation_rate=4)\n    x = residual_block(x, 512, stride=1, dilation_rate=8)\n    x = residual_block(x, 1024, stride=1, dilation_rate=16)\n    \n    # Classifier\n    x = GlobalAveragePooling1D()(x)\n    x = Dense(1024, activation='relu', kernel_initializer=HeNormal())(x)\n    x = Dropout(0.1)(x)\n    x = Dense(512, activation='relu', kernel_initializer=HeNormal())(x)\n    x = Dropout(0.1)(x)\n\n    outputs = Dense(num_classes, activation='sigmoid')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    \n    # Compile the model with Adam optimizer and learning rate scheduling\n    # optimizer = Adam(learning_rate=0.001)\n    # model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n\n# Build the model\ninput_shape = (2500, 1)  # Change according to your EEG data shape\nnum_classes = 1  # Change to the number of classes you have\nmodel = build_resnet(input_shape, num_classes)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.007)\n\nmodel.compile(optimizer=optimizer, \n                      loss='binary_crossentropy', metrics=['accuracy'])\n# Summary of the model\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:04:22.468014Z","iopub.execute_input":"2024-09-16T10:04:22.468878Z","iopub.status.idle":"2024-09-16T10:04:22.956779Z","shell.execute_reply.started":"2024-09-16T10:04:22.468835Z","shell.execute_reply":"2024-09-16T10:04:22.955845Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,352\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,352\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_5 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │        \u001b[38;5;34m512\u001b[0m │ reshape_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m512\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_18 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m24,704\u001b[0m │ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_19 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m49,280\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m8,320\u001b[0m │ multiply_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m2,048\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m2,048\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m98,560\u001b[0m │ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m196,864\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_7 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m8,192\u001b[0m │ reshape_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m8,192\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_7          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m393,728\u001b[0m │ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m786,944\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │    \u001b[38;5;34m131,584\u001b[0m │ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_19 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_8 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m32,768\u001b[0m │ reshape_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m32,768\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_8          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │  \u001b[38;5;34m1,573,888\u001b[0m │ multiply_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_20 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ dropout_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │  \u001b[38;5;34m3,146,752\u001b[0m │ re_lu_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │    \u001b[38;5;34m525,312\u001b[0m │ multiply_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_21 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_9 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m131,072\u001b[0m │ reshape_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │    \u001b[38;5;34m131,072\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_9          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2500\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ re_lu_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m1024\u001b[0m)             │            │ dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ multiply_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │  \u001b[38;5;34m1,049,600\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m524,800\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m513\u001b[0m │ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ reshape_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ reshape_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_7          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">786,944</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │                   │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ reshape_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_8          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,888</span> │ multiply_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,146,752</span> │ re_lu_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ multiply_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ batch_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │ reshape_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multiply_9          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2500</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,941,825\u001b[0m (34.11 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,941,825</span> (34.11 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,929,921\u001b[0m (34.06 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,929,921</span> (34.06 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m11,904\u001b[0m (46.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,904</span> (46.50 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# W/O iterations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.models import load_model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfold_no = 1\nscores = []\nkeras = tf.keras\nhist = []\nmodel = model\n# Create and train the model\n\n\n\n# Checkpoint to save the best model in each fold\nfilepath = f\"/kaggle/working/best_model_folds_{fold_no}.keras\"\nif os.path.exists(filepath):\n    print(\"File exists\")\nelse:\n    print(\"File does not exist\")\n\n\ncheckpoint = ModelCheckpoint(filepath,\n                             monitor='val_accuracy',\n                             verbose=1,\n                             save_best_only=True,\n                             mode='max',\n                            initial_value_threshold = None)\n\n\nlr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.1,  # Factor by which the learning rate will be reduced\n    patience=6,  # Number of epochs with no improvement after which learning rate will be reduced\n    min_lr=1e-6  # Lower bound on the learning rate\n\n)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy',\n                               patience=6, \n                               verbose=1,\n                               mode='max', \n                               baseline=None,\n                               restore_best_weights=True, \n                               start_from_epoch=25)\n\nhist_temp = model.fit(train_series, train_labels_t, validation_data=(val_series, val_labels_t),\n                     epochs=70,\n                     batch_size=8, \n                     callbacks=[checkpoint, lr_scheduler, early_stopping],\n                     verbose=1)\n#model.save(filepath)  # Saves as a SavedModel directory\n\nhist.append(hist_temp)\n# Load the best model and evaluate it\n\n\n\n\nmodel.load_weights(filepath)\nscore = model.evaluate(test_series, test_labels_t, verbose=1)\nscores.append(score[1])  # Assuming 1 is accuracy\nprint(f\"\\nScore for fold {fold_no}: {model.metrics_names[1]} of {score[1]}; {model.metrics_names[0]} of {score[0]}\")\n# calculate metrics = precision, recall, ...\n\ntest_predictions = model.predict(test_series)\ntest_predictions = (test_predictions > 0.5).astype(int)\n\naccuracy = accuracy_score(test_labels_t, test_predictions)\nprecision = precision_score(test_labels_t, test_predictions)\nrecall = recall_score(test_labels_t, test_predictions)\nf1 = f1_score(test_labels_t, test_predictions)\n\n# accuracy_list.append(accuracy)\n# precision_list.append(precision)\n# recall_list.append(recall)\n# f1_list.append(f1)\n\nprint(\"\\nPredictions for Each Subject's Images:\")\nstart_idx = 0\nfor i, (subject_folder, num_images) in enumerate(zip(test_subjects, test_image_counts_per_subject)):\n        end_idx = start_idx + num_images\n        subject_images = test_series[start_idx:end_idx]\n        subject_predictions = (model.predict(subject_images) > 0.5).astype(int)\n        ad_count = sum(subject_predictions == 0)\n        hc_count = sum(subject_predictions == 1)\n        print(f\"Subject {i + 1} ({subject_folder}):\")\n        print(f\"AD count: {ad_count}, HC count: {hc_count}\")\n        start_idx = end_idx\n\n\n# plot the curves for validation and loss \n\n\n# Extract history data\nhistory = hist_temp.history\nepochs = range(1, len(history['loss']) + 1)  # Number of epochs\n\n# Plot training and validation accuracy\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, history['accuracy'], label='Training Accuracy', marker='o')\nplt.plot(epochs, history['val_accuracy'], label='Validation Accuracy', marker='o')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot training and validation loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs, history['loss'], label='Training Loss', marker='o')\nplt.plot(epochs, history['val_loss'], label='Validation Loss', marker='o')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n#fold_no += 1\ntime.sleep(30)\n\n# Calculate and print the average score\n# average_score = np.mean(scores)\n# average_accuracy = np.mean(accuracy_list)\n# average_precision = np.mean(precision_list)\n# average_recall = np.mean(recall_list)\n# average_f1 = np.mean(f1_list)\n# print(f\"\\nAverage Score: {average_score}\")\n# calculate metrics = precision, recall, ...\n\n\n# print(\"\\nAverage Metrics:\")\n# print(f\"Average Precision: {np.mean(average_accuracy):.4f}\")\n# print(f\"Average Precision: {np.mean(average_precision):.4f}\")\n# print(f\"Average Recall: {np.mean(average_recall):.4f}\")\n# print(f\"Average F1 Score: {np.mean(average_f1):.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# with iterations","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.models import load_model\n \niterations = 5\nscores = []\nkeras = tf.keras\nhist = []\nmodel = model\n# Create and train the model\nacc_epoch_list = []\nprecision_epoch_list = []\nf1_epoch_list = [] \nrecall_epoch_list = []\nacc_sbj_list = []\nprecision_sbj_list = []\nf1_sbj_list = []\nrecall_sbj_list = []\n\nfor iteration in range(iterations):\n\n    # Checkpoint to save the best model in each fold\n    filepath = f\"/kaggle/working/best_model_folds_{iteration}.keras\"\n    if os.path.exists(filepath):\n        print(\"File exists\")\n    else:\n        print(\"File does not exist\")\n\n\n    checkpoint = ModelCheckpoint(filepath,\n                                 monitor='val_accuracy',\n                                 verbose=1,\n                                 save_best_only=True,\n                                 mode='max',\n                                initial_value_threshold = None)\n\n\n    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_accuracy',\n        factor=0.1,  # Factor by which the learning rate will be reduced\n        patience=6,  # Number of epochs with no improvement after which learning rate will be reduced\n        min_lr=1e-6  # Lower bound on the learning rate\n\n    )\n\n    early_stopping = EarlyStopping(monitor='val_accuracy',\n                                   patience=6, \n                                   verbose=1,\n                                   mode='max', \n                                   baseline=None,\n                                   restore_best_weights=True, \n                                   start_from_epoch=20)\n\n    hist_temp = model.fit(train_series, train_labels_t, validation_data=(val_series, val_labels_t),\n                         epochs=60,\n                         batch_size=8, \n                         callbacks=[checkpoint, lr_scheduler, early_stopping],\n                         verbose=1)\n    #model.save(filepath)  # Saves as a SavedModel directory\n\n    hist.append(hist_temp)\n    # Load the best model and evaluate it\n\n\n\n\n    model.load_weights(filepath)\n    score = model.evaluate(test_series, test_labels_t, verbose=1)\n    scores.append(score[1])  # Assuming 1 is accuracy\n    #print(f\"\\nScore for fold {fold_no}: {model.metrics_names[1]} of {score[1]}; {model.metrics_names[0]} of {score[0]}\")\n    # calculate metrics = precision, recall, ...\n\n    test_predictions = model.predict(test_series)\n    test_predictions = (test_predictions > 0.5).astype(int)\n    \n    accuracy = accuracy_score(test_labels_t, test_predictions)\n    precision = precision_score(test_labels_t, test_predictions)\n    recall = recall_score(test_labels_t, test_predictions)\n    f1 = f1_score(test_labels_t, test_predictions)\n    print(f\"Accuracy for epoch: {accuracy:.4f}, Precision for epoch: {precision:.4f}, Recall for epoch: {recall:.4f}, F1 for epoch: {f1:.4f}\")\n\n    acc_epoch_list.append(accuracy)\n    precision_epoch_list.append(precision)\n    recall_epoch_list.append(recall)\n    f1_epoch_list.append(f1)\n    \n\n    \n    print(\"\\nPredictions for Each Subject's Images:\")\n    start_idx = 0\n    predicted_subjects_list = []\n    groundtruth_subjects_list = []\n    for i, (subject_folder, num_images) in enumerate(zip(test_subjects, test_image_counts_per_subject)):\n            end_idx = start_idx + num_images\n            subject_images = test_series[start_idx:end_idx]\n            subject_predictions = (model.predict(subject_images) > 0.5).astype(int)\n            ad_count = sum(subject_predictions == 0)\n            hc_count = sum(subject_predictions == 1)\n            print(f\"Subject {i + 1} ({subject_folder}):\")\n            print(f\"AD count: {ad_count}, HC count: {hc_count}\")\n            start_idx = end_idx\n            num = subject_folder[int(subject_folder.find(\"subject\"))+7:]\n            if int(num) < 37: \n                groundtruth_subjects_list.append(0) # AD groundtruth\n            else: \n                groundtruth_subjects_list.append(1) # HC groundtruth\n\n            start_idx = end_idx\n\n            if ad_count > hc_count: \n                predicted_subjects_list.append(0) # AD predicted\n            else:\n                predicted_subjects_list.append(1) # HC predicted\n            \n\n\n    accuracy_sbj = accuracy_score(groundtruth_subjects_list, predicted_subjects_list)\n    precision_sbj = precision_score(groundtruth_subjects_list, predicted_subjects_list)\n    recall_sbj = recall_score(groundtruth_subjects_list, predicted_subjects_list)\n    f1_sbj = f1_score(groundtruth_subjects_list, predicted_subjects_list)\n\n    print(f\"Accuracy for subject: {accuracy_sbj:.4f}, Precision for subject: {precision_sbj:.4f}, Recall for subject: {recall_sbj:.4f}, F1 for subject: {f1_sbj:.4f}\")\n\n    # plot the curves for validation and loss \n    # Extract history data\n    history = hist_temp.history\n    epochs = range(1, len(history['loss']) + 1)  # Number of epochs\n    \n    acc_sbj_list.append(accuracy_sbj)\n    precision_sbj_list.append(precision_sbj)\n    recall_sbj_list.append(recall_sbj)\n    f1_sbj_list.append(f1_sbj)\n    \n\n\n    # Plot training and validation accuracy\n    plt.figure(figsize=(12, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['accuracy'], label='Training Accuracy', marker='o')\n    plt.plot(epochs, history['val_accuracy'], label='Validation Accuracy', marker='o')\n    plt.title(f'Training and Validation Accuracy for iteration:{iteration}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Plot training and validation loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, history['loss'], label='Training Loss', marker='o')\n    plt.plot(epochs, history['val_loss'], label='Validation Loss', marker='o')\n    plt.title(f'Training and Validation Loss for iteration:{iteration}')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n    time.sleep(90)\nprint(f'\\nmean for epoch, accuracy {np.mean(acc_epoch_list)} and std is {np.std(acc_epoch_list)}')\nprint(f'\\nmean for epoch, precision {np.mean(precision_epoch_list)} and std is {np.std(precision_epoch_list)}')\nprint(f'\\nmean for epoch, recall {np.mean(recall_epoch_list)} and std is {np.std(recall_epoch_list)}')\nprint(f'\\nmean for epoch, f1-score {np.mean(f1_epoch_list)} and std is {np.std(f1_epoch_list)}')\n    \nprint(f'\\nmean for subject, accuracy {np.mean(acc_sbj_list)} and std is {np.std(acc_sbj_list)}')\nprint(f'\\nmean for subject, precision {np.mean(precision_sbj_list)} and std is {np.std(precision_sbj_list)}')\nprint(f'\\nmean for subject, recall {np.mean(recall_sbj_list)} and std is {np.std(recall_sbj_list)}')\nprint(f'\\nmean for subject, f1-score {np.mean(f1_sbj_list)} and std is {np.std(f1_sbj_list)}')\n# Calculate and print the average score\n# average_score = np.mean(scores)\n# average_accuracy = np.mean(accuracy_list)\n# average_precision = np.mean(precision_list)\n# average_recall = np.mean(recall_list)\n# average_f1 = np.mean(f1_list)\n# print(f\"\\nAverage Score: {average_score}\")\n# calculate metrics = precision, recall, ...\n\n\n# print(\"\\nAverage Metrics:\")\n# print(f\"Average Precision: {np.mean(average_accuracy):.4f}\")\n# print(f\"Average Precision: {np.mean(average_precision):.4f}\")\n# print(f\"Average Recall: {np.mean(average_recall):.4f}\")\n# print(f\"Average F1 Score: {np.mean(average_f1):.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T10:04:28.320649Z","iopub.execute_input":"2024-09-16T10:04:28.321002Z","iopub.status.idle":"2024-09-16T11:23:36.447705Z","shell.execute_reply.started":"2024-09-16T10:04:28.320968Z","shell.execute_reply":"2024-09-16T11:23:36.446655Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"File exists\nEpoch 1/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.6094 - loss: 1.4848\nEpoch 1: val_accuracy improved from -inf to 0.72593, saving model to /kaggle/working/best_model_folds_0.keras\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 391ms/step - accuracy: 0.6098 - loss: 1.4806 - val_accuracy: 0.7259 - val_loss: 0.7464 - learning_rate: 0.0070\nEpoch 2/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7256 - loss: 0.5414\nEpoch 2: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7255 - loss: 0.5414 - val_accuracy: 0.5963 - val_loss: 1.6966 - learning_rate: 0.0070\nEpoch 3/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7424 - loss: 0.5177\nEpoch 3: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7425 - loss: 0.5175 - val_accuracy: 0.5667 - val_loss: 1.5843 - learning_rate: 0.0070\nEpoch 4/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7538 - loss: 0.4861\nEpoch 4: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.7539 - loss: 0.4860 - val_accuracy: 0.6741 - val_loss: 0.6421 - learning_rate: 0.0070\nEpoch 5/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7506 - loss: 0.4705\nEpoch 5: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7506 - loss: 0.4705 - val_accuracy: 0.6667 - val_loss: 0.6424 - learning_rate: 0.0070\nEpoch 6/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7749 - loss: 0.4746\nEpoch 6: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7749 - loss: 0.4745 - val_accuracy: 0.6296 - val_loss: 0.7742 - learning_rate: 0.0070\nEpoch 7/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7940 - loss: 0.4350\nEpoch 7: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7940 - loss: 0.4350 - val_accuracy: 0.6074 - val_loss: 1.1826 - learning_rate: 0.0070\nEpoch 8/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7839 - loss: 0.4358\nEpoch 8: val_accuracy did not improve from 0.72593\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7839 - loss: 0.4357 - val_accuracy: 0.6704 - val_loss: 0.6351 - learning_rate: 7.0000e-04\nEpoch 9/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8078 - loss: 0.3981\nEpoch 9: val_accuracy improved from 0.72593 to 0.72963, saving model to /kaggle/working/best_model_folds_0.keras\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 172ms/step - accuracy: 0.8079 - loss: 0.3981 - val_accuracy: 0.7296 - val_loss: 0.6362 - learning_rate: 7.0000e-04\nEpoch 10/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8243 - loss: 0.3723\nEpoch 10: val_accuracy did not improve from 0.72963\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8243 - loss: 0.3723 - val_accuracy: 0.7074 - val_loss: 0.5650 - learning_rate: 7.0000e-04\nEpoch 11/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8074 - loss: 0.3909\nEpoch 11: val_accuracy improved from 0.72963 to 0.74815, saving model to /kaggle/working/best_model_folds_0.keras\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 172ms/step - accuracy: 0.8074 - loss: 0.3909 - val_accuracy: 0.7481 - val_loss: 0.5879 - learning_rate: 7.0000e-04\nEpoch 12/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7954 - loss: 0.3972\nEpoch 12: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.7954 - loss: 0.3971 - val_accuracy: 0.6704 - val_loss: 0.6809 - learning_rate: 7.0000e-04\nEpoch 13/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8143 - loss: 0.3730\nEpoch 13: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8144 - loss: 0.3730 - val_accuracy: 0.7370 - val_loss: 0.6097 - learning_rate: 7.0000e-04\nEpoch 14/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8125 - loss: 0.3646\nEpoch 14: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8125 - loss: 0.3646 - val_accuracy: 0.5926 - val_loss: 1.0863 - learning_rate: 7.0000e-04\nEpoch 15/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8224 - loss: 0.3712\nEpoch 15: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8225 - loss: 0.3711 - val_accuracy: 0.6926 - val_loss: 0.6460 - learning_rate: 7.0000e-04\nEpoch 16/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8380 - loss: 0.3343\nEpoch 16: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8380 - loss: 0.3343 - val_accuracy: 0.7222 - val_loss: 0.7264 - learning_rate: 7.0000e-04\nEpoch 17/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8505 - loss: 0.3447\nEpoch 17: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8505 - loss: 0.3447 - val_accuracy: 0.6926 - val_loss: 0.9310 - learning_rate: 7.0000e-04\nEpoch 18/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8566 - loss: 0.3368\nEpoch 18: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8565 - loss: 0.3368 - val_accuracy: 0.6778 - val_loss: 0.9785 - learning_rate: 7.0000e-05\nEpoch 19/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8653 - loss: 0.3100\nEpoch 19: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8652 - loss: 0.3102 - val_accuracy: 0.6741 - val_loss: 0.9912 - learning_rate: 7.0000e-05\nEpoch 20/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8613 - loss: 0.3097\nEpoch 20: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8613 - loss: 0.3098 - val_accuracy: 0.6593 - val_loss: 1.0498 - learning_rate: 7.0000e-05\nEpoch 21/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8489 - loss: 0.3295\nEpoch 21: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8489 - loss: 0.3295 - val_accuracy: 0.6741 - val_loss: 1.0320 - learning_rate: 7.0000e-05\nEpoch 22/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8485 - loss: 0.3457\nEpoch 22: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8485 - loss: 0.3456 - val_accuracy: 0.6556 - val_loss: 1.0787 - learning_rate: 7.0000e-05\nEpoch 23/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8447 - loss: 0.3275\nEpoch 23: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8447 - loss: 0.3275 - val_accuracy: 0.6741 - val_loss: 0.9821 - learning_rate: 7.0000e-05\nEpoch 24/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8604 - loss: 0.3131\nEpoch 24: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8605 - loss: 0.3131 - val_accuracy: 0.6556 - val_loss: 1.0343 - learning_rate: 7.0000e-06\nEpoch 25/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8363 - loss: 0.3394\nEpoch 25: val_accuracy did not improve from 0.74815\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8364 - loss: 0.3394 - val_accuracy: 0.6444 - val_loss: 1.0540 - learning_rate: 7.0000e-06\nEpoch 26/60\n\u001b[1m 26/162\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 161ms/step - accuracy: 0.8643 - loss: 0.3422File exists\nEpoch 1/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8070 - loss: 0.3722\nEpoch 1: val_accuracy improved from -inf to 0.63704, saving model to /kaggle/working/best_model_folds_1.keras\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 172ms/step - accuracy: 0.8071 - loss: 0.3722 - val_accuracy: 0.6370 - val_loss: 1.0668 - learning_rate: 7.0000e-04\nEpoch 2/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8506 - loss: 0.3369\nEpoch 2: val_accuracy did not improve from 0.63704\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8505 - loss: 0.3371 - val_accuracy: 0.6074 - val_loss: 0.8150 - learning_rate: 7.0000e-04\nEpoch 3/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8214 - loss: 0.3455\nEpoch 3: val_accuracy improved from 0.63704 to 0.68519, saving model to /kaggle/working/best_model_folds_1.keras\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 172ms/step - accuracy: 0.8213 - loss: 0.3456 - val_accuracy: 0.6852 - val_loss: 0.7387 - learning_rate: 7.0000e-04\nEpoch 4/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8099 - loss: 0.3756\nEpoch 4: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8100 - loss: 0.3755 - val_accuracy: 0.5333 - val_loss: 1.3511 - learning_rate: 7.0000e-04\nEpoch 5/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8298 - loss: 0.3494\nEpoch 5: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8298 - loss: 0.3494 - val_accuracy: 0.5593 - val_loss: 1.3836 - learning_rate: 7.0000e-04\nEpoch 6/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8594 - loss: 0.3234\nEpoch 6: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8594 - loss: 0.3234 - val_accuracy: 0.5741 - val_loss: 1.6717 - learning_rate: 7.0000e-04\nEpoch 7/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8494 - loss: 0.3500\nEpoch 7: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8493 - loss: 0.3501 - val_accuracy: 0.6296 - val_loss: 1.0910 - learning_rate: 7.0000e-04\nEpoch 8/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8454 - loss: 0.3345\nEpoch 8: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8454 - loss: 0.3344 - val_accuracy: 0.5333 - val_loss: 2.2286 - learning_rate: 7.0000e-04\nEpoch 9/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8612 - loss: 0.3167\nEpoch 9: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8612 - loss: 0.3168 - val_accuracy: 0.6296 - val_loss: 1.1114 - learning_rate: 7.0000e-04\nEpoch 10/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8372 - loss: 0.3245\nEpoch 10: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8373 - loss: 0.3244 - val_accuracy: 0.6037 - val_loss: 1.2206 - learning_rate: 7.0000e-05\nEpoch 11/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8478 - loss: 0.3109\nEpoch 11: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8478 - loss: 0.3109 - val_accuracy: 0.6037 - val_loss: 1.2335 - learning_rate: 7.0000e-05\nEpoch 12/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8438 - loss: 0.3328\nEpoch 12: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8439 - loss: 0.3326 - val_accuracy: 0.5926 - val_loss: 1.3036 - learning_rate: 7.0000e-05\nEpoch 13/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8794 - loss: 0.2911\nEpoch 13: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8793 - loss: 0.2910 - val_accuracy: 0.6037 - val_loss: 1.2020 - learning_rate: 7.0000e-05\nEpoch 14/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8467 - loss: 0.3105\nEpoch 14: val_accuracy did not improve from 0.68519\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8467 - loss: 0.3104 - val_accuracy: 0.6000 - val_loss: 1.2413 - learning_rate: 7.0000e-05\nEpoch 15/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8747 - loss: 0.2619\nEpoch 13: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8749 - loss: 0.2619 - val_accuracy: 0.6481 - val_loss: 0.8741 - learning_rate: 7.0000e-05\nEpoch 14/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8826 - loss: 0.2742\nEpoch 14: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8826 - loss: 0.2742 - val_accuracy: 0.6370 - val_loss: 0.9118 - learning_rate: 7.0000e-05\nEpoch 15/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8990 - loss: 0.2535\nEpoch 15: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8989 - loss: 0.2535 - val_accuracy: 0.6074 - val_loss: 0.9545 - learning_rate: 7.0000e-05\nEpoch 16/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8665 - loss: 0.2764\nEpoch 16: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8666 - loss: 0.2763 - val_accuracy: 0.6556 - val_loss: 0.8256 - learning_rate: 7.0000e-05\nEpoch 17/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8763 - loss: 0.2666\nEpoch 17: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8764 - loss: 0.2665 - val_accuracy: 0.6333 - val_loss: 0.8795 - learning_rate: 7.0000e-06\nEpoch 18/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8982 - loss: 0.2441\nEpoch 18: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8981 - loss: 0.2442 - val_accuracy: 0.6296 - val_loss: 0.8923 - learning_rate: 7.0000e-06\nEpoch 19/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8898 - loss: 0.2596\nEpoch 19: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8898 - loss: 0.2596 - val_accuracy: 0.6296 - val_loss: 0.8957 - learning_rate: 7.0000e-06\nEpoch 20/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8940 - loss: 0.2739\nEpoch 20: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8939 - loss: 0.2738 - val_accuracy: 0.6222 - val_loss: 0.8980 - learning_rate: 7.0000e-06\nEpoch 21/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8995 - loss: 0.2294\nEpoch 21: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8994 - loss: 0.2296 - val_accuracy: 0.6185 - val_loss: 0.9162 - learning_rate: 7.0000e-06\nEpoch 22/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8903 - loss: 0.2433\nEpoch 22: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.8903 - loss: 0.2434 - val_accuracy: 0.6296 - val_loss: 0.9118 - learning_rate: 7.0000e-06\nEpoch 23/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9181 - loss: 0.2260\nEpoch 23: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 169ms/step - accuracy: 0.9180 - loss: 0.2262 - val_accuracy: 0.6333 - val_loss: 0.9038 - learning_rate: 1.0000e-06\nEpoch 24/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8975 - loss: 0.2613\nEpoch 24: val_accuracy did not improve from 0.67407\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.8975 - loss: 0.2613 - val_accuracy: 0.6222 - val_loss: 0.9147 - learning_rate: 1.0000e-06\nEpoch 25/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9184 - loss: 0.1982\nEpoch 9: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9184 - loss: 0.1983 - val_accuracy: 0.5481 - val_loss: 1.1388 - learning_rate: 7.0000e-05\nEpoch 10/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9100 - loss: 0.2157\nEpoch 10: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9100 - loss: 0.2157 - val_accuracy: 0.5519 - val_loss: 1.1719 - learning_rate: 7.0000e-05\nEpoch 11/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9124 - loss: 0.1950\nEpoch 11: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9124 - loss: 0.1950 - val_accuracy: 0.5370 - val_loss: 1.2434 - learning_rate: 7.0000e-05\nEpoch 12/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9157 - loss: 0.2055\nEpoch 12: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9157 - loss: 0.2055 - val_accuracy: 0.5407 - val_loss: 1.3077 - learning_rate: 7.0000e-05\nEpoch 13/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9093 - loss: 0.2194\nEpoch 13: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9093 - loss: 0.2194 - val_accuracy: 0.5519 - val_loss: 1.1620 - learning_rate: 7.0000e-05\nEpoch 14/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9192 - loss: 0.2088\nEpoch 14: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9191 - loss: 0.2088 - val_accuracy: 0.5111 - val_loss: 1.4161 - learning_rate: 7.0000e-05\nEpoch 15/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9219 - loss: 0.1926\nEpoch 15: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9218 - loss: 0.1927 - val_accuracy: 0.5296 - val_loss: 1.3525 - learning_rate: 7.0000e-06\nEpoch 16/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9273 - loss: 0.1836\nEpoch 16: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9273 - loss: 0.1837 - val_accuracy: 0.5333 - val_loss: 1.3335 - learning_rate: 7.0000e-06\nEpoch 17/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9252 - loss: 0.1899\nEpoch 17: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9251 - loss: 0.1899 - val_accuracy: 0.5407 - val_loss: 1.3101 - learning_rate: 7.0000e-06\nEpoch 18/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9162 - loss: 0.1975\nEpoch 18: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 168ms/step - accuracy: 0.9162 - loss: 0.1975 - val_accuracy: 0.5444 - val_loss: 1.2934 - learning_rate: 7.0000e-06\nEpoch 19/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9274 - loss: 0.1911\nEpoch 19: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9274 - loss: 0.1911 - val_accuracy: 0.5333 - val_loss: 1.3213 - learning_rate: 7.0000e-06\nEpoch 20/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9273 - loss: 0.1923\nEpoch 20: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9273 - loss: 0.1924 - val_accuracy: 0.5444 - val_loss: 1.3085 - learning_rate: 7.0000e-06\nEpoch 21/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9159 - loss: 0.1924\nEpoch 21: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 168ms/step - accuracy: 0.9159 - loss: 0.1925 - val_accuracy: 0.5333 - val_loss: 1.3351 - learning_rate: 1.0000e-06\nEpoch 22/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9175 - loss: 0.2033\nEpoch 22: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9175 - loss: 0.2034 - val_accuracy: 0.5333 - val_loss: 1.3304 - learning_rate: 1.0000e-06\nEpoch 23/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9254 - loss: 0.1866\nEpoch 23: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9253 - loss: 0.1867 - val_accuracy: 0.5333 - val_loss: 1.3147 - learning_rate: 1.0000e-06\nEpoch 24/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9242 - loss: 0.2025\nEpoch 24: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9243 - loss: 0.2025 - val_accuracy: 0.5333 - val_loss: 1.3371 - learning_rate: 1.0000e-06\nEpoch 25/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9146 - loss: 0.1957\nEpoch 25: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9146 - loss: 0.1957 - val_accuracy: 0.5333 - val_loss: 1.3234 - learning_rate: 1.0000e-06\nEpoch 26/60\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9137 - loss: 0.2155\nEpoch 26: val_accuracy did not improve from 0.70741\n\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 167ms/step - accuracy: 0.9138 - loss: 0.2154 - val_accuracy: 0.5444 - val_loss: 1.3101 - learning_rate: 1.0000e-06\nEpoch 27/60\n\u001b[1m102/162\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 160ms/step - accuracy: 0.9113 - loss: 0.2076","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"\nmean for epoch, accuracy 0.7948717948717949 and std is 0.03307592922378891\n\nmean for epoch, precision 0.8828243095140469 and std is 0.0326525455436973\n\nmean for epoch, recall 0.719047619047619 and std is 0.10052018896730486\n\nmean for epoch, f1-score 0.7870498556965952 and std is 0.047805105050596236\n\nmean for subject, accuracy 0.8153846153846154 and std is 0.07844645405527362\n\nmean for subject, precision 0.9016666666666667 and std is 0.08373237791386978\n\nmean for subject, recall 0.7428571428571429 and std is 0.13997084244475305\n\nmean for subject, f1-score 0.8071794871794872 and std is 0.08771179870360186\n","output_type":"stream"}]},{"cell_type":"code","source":"np.mean(acc_sbj_list)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T16:29:08.949431Z","iopub.execute_input":"2024-09-15T16:29:08.949930Z","iopub.status.idle":"2024-09-15T16:29:08.956556Z","shell.execute_reply.started":"2024-09-15T16:29:08.949883Z","shell.execute_reply":"2024-09-15T16:29:08.955649Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.9076923076923078"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}