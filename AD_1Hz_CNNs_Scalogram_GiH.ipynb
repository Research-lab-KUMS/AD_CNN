{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Makhloughi"
      ],
      "metadata": {
        "id": "JXNNzokAGZ3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmGL1r444dDF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential, Model, clone_model\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Input, ConvLSTM2D,MaxPooling3D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D, MaxPool2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, InceptionV3, DenseNet121, EfficientNetB2\n",
        "from tensorflow.keras.layers import LSTM, GRU, TimeDistributed, Input\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9DE0DZG4hPB",
        "outputId": "d39b20ea-02f6-4306-ebf8-182c2a57d8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Occipital"
      ],
      "metadata": {
        "id": "aIPsAkSqnTab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Final_1Hz/lobes/Occipital/'\n",
        "\n",
        "\n",
        "def extract_numeric_part(folder_name):\n",
        "    return int(folder_name.split('_')[-1])\n",
        "\n",
        "folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))], key=extract_numeric_part)\n",
        "\n",
        "subject_folders, labels = [], []\n",
        "\n",
        "for folder_name in folders:\n",
        "    subject_num = int(folder_name.split('_')[-1])\n",
        "    subject_folder = os.path.join(data_dir, folder_name)\n",
        "    subject_folders.append(subject_folder)\n",
        "\n",
        "    if subject_num <= 36:\n",
        "        labels.append(0)  # AD group\n",
        "    elif 37 <= subject_num <= 65:\n",
        "        labels.append(1)  # HC group\n",
        "\n",
        "subject_folders = np.array(subject_folders)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "fm00YzZtdF-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(subjects, labels):\n",
        "    images, labels_t = [], []\n",
        "    for subject_folder, label in zip(subjects, labels):\n",
        "        for filename in os.listdir(subject_folder):\n",
        "            img_path = os.path.join(subject_folder, filename.decode())\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "\n",
        "                width, height = img.size\n",
        "                left = 99\n",
        "                top = 50\n",
        "                right = width - 176\n",
        "                bottom = height - 73\n",
        "                img = img.crop((left, top, right, bottom))\n",
        "\n",
        "                img = img.resize((224, 224))\n",
        "                img_array = img_to_array(img)\n",
        "                img_array = img_array / 255.0\n",
        "\n",
        "                images.append(img_array)\n",
        "                labels_t.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image: {img_path}, {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels_t)\n"
      ],
      "metadata": {
        "id": "ktvVT0n9nedj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(subject_folders, labels):\n",
        "    train_subjects, test_subjects, train_labels, test_labels = train_test_split(subject_folders, labels, test_size=0.2, stratify=labels)\n",
        "\n",
        "    train_subjects, val_subjects, train_labels, val_labels = train_test_split(train_subjects, train_labels, test_size=0.1, stratify=train_labels)\n",
        "\n",
        "    train_images, train_labels_t = load_images_and_labels(train_subjects, train_labels)\n",
        "    val_images, val_labels_t = load_images_and_labels(val_subjects, val_labels)\n",
        "\n",
        "    test_image_counts_per_subject = [len(os.listdir(folder)) for folder in test_subjects]\n",
        "\n",
        "    test_images, test_labels_t = load_images_and_labels(test_subjects, test_labels)\n",
        "\n",
        "    return train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject\n"
      ],
      "metadata": {
        "id": "opXdIhf_niq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_model(base_model):\n",
        "    model = clone_model(base_model)\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=predictions)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ZAJ11C0VnjZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom callback to start saving checkpoints from epoch 30\n",
        "class CustomCheckpoint(ModelCheckpoint):\n",
        "    def __init__(self, start_epoch, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.start_epoch = start_epoch\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch >= self.start_epoch:\n",
        "            super().on_epoch_end(epoch, logs)\n",
        "\n",
        "def train_and_evaluate_model(base_model, subject_folders, labels, num_epochs=50, num_iterations=5, model_name='model'):\n",
        "    accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        print(f\"\\nIteration {iteration + 1}:\")\n",
        "\n",
        "        model = create_new_model(base_model)\n",
        "\n",
        "        train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject = load_and_preprocess_data(subject_folders, labels)\n",
        "\n",
        "        train_data = list(zip(train_images, train_labels_t))\n",
        "        np.random.shuffle(train_data)\n",
        "        train_images, train_labels_t = zip(*train_data)\n",
        "\n",
        "        val_data = list(zip(val_images, val_labels_t))\n",
        "        np.random.shuffle(val_data)\n",
        "        val_images, val_labels_t = zip(*val_data)\n",
        "\n",
        "        train_images, train_labels_t = np.array(train_images), np.array(train_labels_t)\n",
        "        val_images, val_labels_t = np.array(val_images), np.array(val_labels_t)\n",
        "\n",
        "        checkpoint_dir = '/content'\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        local_checkpoint_filepath = os.path.join(checkpoint_dir, f\"{model_name}_best_weights_iteration_{iteration + 1}.h5\")\n",
        "        drive_checkpoint_filepath = f'/content/drive/My Drive/{model_name}_best_weights_iteration_{iteration + 1}.h5'\n",
        "\n",
        "        checkpoint_callback = CustomCheckpoint(\n",
        "            start_epoch=30,\n",
        "            filepath=local_checkpoint_filepath,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        class LearningRateLogger(Callback):\n",
        "            def on_epoch_end(self, epoch, logs=None):\n",
        "                logs = logs or {}\n",
        "                logs['learning_rate'] = self.model.optimizer.learning_rate.numpy()\n",
        "        lr_logger = LearningRateLogger()\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', baseline=None, restore_best_weights=False, start_from_epoch=30)\n",
        "\n",
        "        history = model.fit(train_images, train_labels_t, epochs=num_epochs, batch_size=32, validation_data=(val_images, val_labels_t), callbacks=[checkpoint_callback, early_stopping, lr_logger], verbose=1)\n",
        "\n",
        "        if os.path.exists(local_checkpoint_filepath):\n",
        "            print(f\"Best weights saved locally at: {local_checkpoint_filepath}\")\n",
        "\n",
        "            shutil.copy(local_checkpoint_filepath, drive_checkpoint_filepath)\n",
        "            if os.path.exists(drive_checkpoint_filepath):\n",
        "                print(f\"Best weights also copied to Google Drive at: {drive_checkpoint_filepath}\")\n",
        "            else:\n",
        "                print(f\"Failed to copy best weights to Google Drive at: {drive_checkpoint_filepath}\")\n",
        "        else:\n",
        "            print(f\"Failed to save best weights locally at: {local_checkpoint_filepath}\")\n",
        "\n",
        "        model.load_weights(local_checkpoint_filepath)\n",
        "\n",
        "        test_predictions = model.predict(test_images)\n",
        "        test_predictions = (test_predictions > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(test_labels_t, test_predictions)\n",
        "        precision = precision_score(test_labels_t, test_predictions)\n",
        "        recall = recall_score(test_labels_t, test_predictions)\n",
        "        f1 = f1_score(test_labels_t, test_predictions)\n",
        "\n",
        "        accuracy_list.append(accuracy)\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "        print(\"ModelCheckpoint callback triggered and saved the best weights.\")\n",
        "\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Model accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        file_name = f'{model_name}_accuracy_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        file_name = f'{model_name}_loss_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        cm = confusion_matrix(test_labels_t, test_predictions)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=['AD', 'HC'], yticklabels=['AD', 'HC'])\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'Confusion Matrix - {model_name} - Iteration {iteration + 1}')\n",
        "        file_name = f'{model_name}_confusion_matrix_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "\n",
        "        print(\"\\nPredictions for Each Subject's Images:\")\n",
        "        start_idx = 0\n",
        "        for i, (subject_folder, num_images) in enumerate(zip(test_subjects, test_image_counts_per_subject)):\n",
        "            end_idx = start_idx + num_images\n",
        "            subject_images = test_images[start_idx:end_idx]\n",
        "            subject_predictions = (model.predict(subject_images) > 0.5).astype(int)\n",
        "            ad_count = sum(subject_predictions == 0)\n",
        "            hc_count = sum(subject_predictions == 1)\n",
        "            print(f\"Subject {i + 1} ({subject_folder}):\")\n",
        "            print(f\"AD count: {ad_count}, HC count: {hc_count}\")\n",
        "            start_idx = end_idx\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nAverage Metrics:\")\n",
        "    print(f\"Average Accuracy: {np.mean(accuracy_list):.4f}\")\n",
        "    print(f\"Average Precision: {np.mean(precision_list):.4f}\")\n",
        "    print(f\"Average Recall: {np.mean(recall_list):.4f}\")\n",
        "    print(f\"Average F1 Score: {np.mean(f1_list):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "HGCrJfr9ShtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63x4Sc0NUKdy"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "AcwK5Vd7pDzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # x = model.output\n",
        "    # x = Flatten()(x)\n",
        "    # x = Dense(128)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "    # x = Dense(256)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "model_name = 'vgg16_Occipital'\n",
        "train_and_evaluate_model(vgg16_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "djsR2B8-HxZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOUfJlk7gcWv"
      },
      "source": [
        "## ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "ZXDe6bu9m9yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ResNet50_Occipital'\n",
        "train_and_evaluate_model(ResNet50_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "5OMHbX9Am9yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## InceptionV3"
      ],
      "metadata": {
        "id": "EIeG6T79TGkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Incep_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "zY3BgaSGFPW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'InceptionV3_Occipital'\n",
        "train_and_evaluate_model(Incep_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "6REQfnoHFVfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet121"
      ],
      "metadata": {
        "id": "nAfPeleqFZvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dense_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483678ff-7ca5-4dc6-b561-d5e6a499c90f",
        "id": "IJbTfvHXxkKa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet121_Occipital'\n",
        "train_and_evaluate_model(Dense_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "GygF8sxIxkKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal"
      ],
      "metadata": {
        "id": "KCQ9NZ1_YyUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Final_1Hz/lobes/Temporal/'\n",
        "\n",
        "\n",
        "def extract_numeric_part(folder_name):\n",
        "    return int(folder_name.split('_')[-1])\n",
        "\n",
        "folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))], key=extract_numeric_part)\n",
        "\n",
        "subject_folders, labels = [], []\n",
        "\n",
        "for folder_name in folders:\n",
        "    subject_num = int(folder_name.split('_')[-1])\n",
        "    subject_folder = os.path.join(data_dir, folder_name)\n",
        "    subject_folders.append(subject_folder)\n",
        "\n",
        "    if subject_num <= 36:\n",
        "        labels.append(0)  # AD group\n",
        "    elif 37 <= subject_num <= 65:\n",
        "        labels.append(1)  # HC group\n",
        "\n",
        "subject_folders = np.array(subject_folders)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "EQrsTOs3UMOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(subjects, labels):\n",
        "    images, labels_t = [], []\n",
        "    for subject_folder, label in zip(subjects, labels):\n",
        "        for filename in os.listdir(subject_folder):\n",
        "            img_path = os.path.join(subject_folder, filename.decode())\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "\n",
        "                width, height = img.size\n",
        "                left = 99\n",
        "                top = 50\n",
        "                right = width - 176\n",
        "                bottom = height - 73\n",
        "                img = img.crop((left, top, right, bottom))\n",
        "\n",
        "                img = img.resize((224, 224))\n",
        "                img_array = img_to_array(img)\n",
        "                img_array = img_array / 255.0\n",
        "\n",
        "                images.append(img_array)\n",
        "                labels_t.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image: {img_path}, {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels_t)\n"
      ],
      "metadata": {
        "id": "HZQJVBAfUMOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(subject_folders, labels):\n",
        "    train_subjects, test_subjects, train_labels, test_labels = train_test_split(subject_folders, labels, test_size=0.2, stratify=labels)\n",
        "\n",
        "    train_subjects, val_subjects, train_labels, val_labels = train_test_split(train_subjects, train_labels, test_size=0.1, stratify=train_labels)\n",
        "\n",
        "    train_images, train_labels_t = load_images_and_labels(train_subjects, train_labels)\n",
        "    val_images, val_labels_t = load_images_and_labels(val_subjects, val_labels)\n",
        "\n",
        "    test_image_counts_per_subject = [len(os.listdir(folder)) for folder in test_subjects]\n",
        "\n",
        "    test_images, test_labels_t = load_images_and_labels(test_subjects, test_labels)\n",
        "\n",
        "    return train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject\n"
      ],
      "metadata": {
        "id": "eZATt9EzUMOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_model(base_model):\n",
        "    model = clone_model(base_model)\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=predictions)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "UsbOboKCUMOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomCheckpoint(ModelCheckpoint):\n",
        "    def __init__(self, start_epoch, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.start_epoch = start_epoch\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch >= self.start_epoch:\n",
        "            super().on_epoch_end(epoch, logs)\n",
        "\n",
        "# def lr_schedule(epoch, lr):\n",
        "#     if epoch > 0 and epoch % 10 == 0:\n",
        "#         return lr * (1/3)\n",
        "#     return lr\n",
        "\n",
        "def train_and_evaluate_model(base_model, num_epochs=50, num_iterations=5, model_name='model'):\n",
        "    accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        print(f\"\\nIteration {iteration + 1}:\")\n",
        "\n",
        "        model = create_new_model(base_model)\n",
        "\n",
        "        train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject = load_and_preprocess_data(subject_folders, labels)\n",
        "\n",
        "        train_data = list(zip(train_images, train_labels_t))\n",
        "        np.random.shuffle(train_data)\n",
        "        train_images, train_labels_t = zip(*train_data)\n",
        "\n",
        "        val_data = list(zip(val_images, val_labels_t))\n",
        "        np.random.shuffle(val_data)\n",
        "        val_images, val_labels_t = zip(*val_data)\n",
        "\n",
        "        test_data = list(zip(val_images, test_labels_t))\n",
        "        np.random.shuffle(test_data)\n",
        "        test_images, test_labels_t = zip(*test_data)\n",
        "\n",
        "        train_images, train_labels_t = np.array(train_images), np.array(train_labels_t)\n",
        "        val_images, val_labels_t = np.array(val_images), np.array(val_labels_t)\n",
        "        test_images, test_labels_t = np.array(test_images), np.array(test_labels_t)\n",
        "\n",
        "\n",
        "        checkpoint_dir = '/content'\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        local_checkpoint_filepath = os.path.join(checkpoint_dir, f\"{model_name}_best_weights_iteration_{iteration + 1}.h5\")\n",
        "        drive_checkpoint_filepath = f'/content/drive/My Drive/{model_name}_best_weights_iteration_{iteration + 1}.h5'\n",
        "\n",
        "        checkpoint_callback = CustomCheckpoint(\n",
        "            start_epoch=30,\n",
        "            filepath=local_checkpoint_filepath,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        class LearningRateLogger(Callback):\n",
        "            def on_epoch_end(self, epoch, logs=None):\n",
        "                logs = logs or {}\n",
        "                logs['learning_rate'] = self.model.optimizer.learning_rate.numpy()\n",
        "        lr_logger = LearningRateLogger()\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', baseline=None, restore_best_weights=False, start_from_epoch=30)\n",
        "\n",
        "        # lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "        history = model.fit(train_images, train_labels_t, epochs=num_epochs, batch_size=128, validation_data=(val_images, val_labels_t), callbacks=[checkpoint_callback, early_stopping, lr_logger], verbose=1)\n",
        "\n",
        "        if os.path.exists(local_checkpoint_filepath):\n",
        "            print(f\"Best weights saved locally at: {local_checkpoint_filepath}\")\n",
        "\n",
        "            shutil.copy(local_checkpoint_filepath, drive_checkpoint_filepath)\n",
        "            if os.path.exists(drive_checkpoint_filepath):\n",
        "                print(f\"Best weights also copied to Google Drive at: {drive_checkpoint_filepath}\")\n",
        "            else:\n",
        "                print(f\"Failed to copy best weights to Google Drive at: {drive_checkpoint_filepath}\")\n",
        "        else:\n",
        "            print(f\"Failed to save best weights locally at: {local_checkpoint_filepath}\")\n",
        "\n",
        "        model.load_weights(local_checkpoint_filepath)\n",
        "\n",
        "        test_predictions = model.predict(test_images)\n",
        "        test_predictions = (test_predictions > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(test_labels_t, test_predictions)\n",
        "        precision = precision_score(test_labels_t, test_predictions)\n",
        "        recall = recall_score(test_labels_t, test_predictions)\n",
        "        f1 = f1_score(test_labels_t, test_predictions)\n",
        "\n",
        "        accuracy_list.append(accuracy)\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "        print(\"ModelCheckpoint callback triggered and saved the best weights.\")\n",
        "\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Model accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        file_name = f'{model_name}_accuracy_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        file_name = f'{model_name}_loss_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        cm = confusion_matrix(test_labels_t, test_predictions)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=['AD', 'HC'], yticklabels=['AD', 'HC'])\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'Confusion Matrix - {model_name} - Iteration {iteration + 1}')\n",
        "        file_name = f'{model_name}_confusion_matrix_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        print(\"\\nPredictions for Each Subject's Images:\")\n",
        "        start_idx = 0\n",
        "        for i, (subject_folder, num_images) in enumerate(zip(test_subjects, test_image_counts_per_subject)):\n",
        "            end_idx = start_idx + num_images\n",
        "            subject_images = test_images[start_idx:end_idx]\n",
        "            subject_predictions = (model.predict(subject_images) > 0.5).astype(int)\n",
        "            ad_count = sum(subject_predictions == 0)\n",
        "            hc_count = sum(subject_predictions == 1)\n",
        "            print(f\"Subject {i + 1} ({subject_folder}):\")\n",
        "            print(f\"AD count: {ad_count}, HC count: {hc_count}\")\n",
        "            start_idx = end_idx\n",
        "\n",
        "    print(\"\\nAverage Metrics:\")\n",
        "    print(f\"Average Accuracy: {np.mean(accuracy_list):.4f}\")\n",
        "    print(f\"Average Precision: {np.mean(precision_list):.4f}\")\n",
        "    print(f\"Average Recall: {np.mean(recall_list):.4f}\")\n",
        "    print(f\"Average F1 Score: {np.mean(f1_list):.4f}\")\n"
      ],
      "metadata": {
        "id": "BWNTQJ_xUMOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcPe7gSvYwc5"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40df566-179d-42f0-a719-644a39c65730",
        "id": "SrooIy0qYwc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'vgg16_Temporal'\n",
        "train_and_evaluate_model(vgg16_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "nRudfxmtYwc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "wAo1cTFF7ZVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e006f7e4-3902-4cf0-e0fc-022890729e8f",
        "id": "kEJMEzaL7dhd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet50_Temporal_1'\n",
        "train_and_evaluate_model(resnet_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "0B2bAzNbb9Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## InceptionV3"
      ],
      "metadata": {
        "id": "tJGpdt_n4Uqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'InceptionV3_Temporal'\n",
        "train_and_evaluate_model(incep_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "vPlnoDaw4Wsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet121"
      ],
      "metadata": {
        "id": "BFpL67y4HphE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dense_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483678ff-7ca5-4dc6-b561-d5e6a499c90f",
        "id": "AoFJkwkdHphF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet121_Temporal'\n",
        "train_and_evaluate_model(Dense_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "DnngfrNhHphH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parietal"
      ],
      "metadata": {
        "id": "xMiJIGaExEC6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyJN4pVTIQqx"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "Rqoyg1CzIQqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # x = model.output\n",
        "    # x = Flatten()(x)\n",
        "    # x = Dense(128)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "    # x = Dense(256)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "model_name = 'vgg16_Parietal'\n",
        "train_and_evaluate_model(vgg16_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "gfRuclBMIQqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "VutksNh9INsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e006f7e4-3902-4cf0-e0fc-022890729e8f",
        "id": "pJScaFD-INsf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet50_Parietal'\n",
        "train_and_evaluate_model(resnet_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "LRV2wzslINsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgDEHTVixSXq"
      },
      "source": [
        "## Inception v3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incep_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e537554f-fe57-43e7-9e15-44a8d6b25ab5",
        "id": "ubkjPR8CxSX2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'InceptionV3_Parietal'\n",
        "train_and_evaluate_model(incep_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "ktnKD-G2xSX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet121"
      ],
      "metadata": {
        "id": "_Myv4eybIXg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dense_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483678ff-7ca5-4dc6-b561-d5e6a499c90f",
        "id": "UK-VDKx-IXg-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet121_Parietal'\n",
        "train_and_evaluate_model(Dense_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "fJ_-ZxhFIXg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Central"
      ],
      "metadata": {
        "id": "smXRLmQJIdl5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTFUMvkVIdl6"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "krsFzdS-Idl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # x = model.output\n",
        "    # x = Flatten()(x)\n",
        "    # x = Dense(128)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "    # x = Dense(256)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "model_name = 'vgg16_Central'\n",
        "train_and_evaluate_model(vgg16_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "Qf34T8CAIdl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "0gv36FRBIdl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e006f7e4-3902-4cf0-e0fc-022890729e8f",
        "id": "_Tzq5wKOIdl-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet50_Centrall'\n",
        "train_and_evaluate_model(resnet_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "MGp1KTt1Idl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQhR9XcLIdmA"
      },
      "source": [
        "## Inception v3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incep_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e537554f-fe57-43e7-9e15-44a8d6b25ab5",
        "id": "ROszENoHIdmC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'InceptionV3_Central'\n",
        "train_and_evaluate_model(incep_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "oQqDxfHMIdmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet121"
      ],
      "metadata": {
        "id": "TXwS1qa0IdmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dense_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483678ff-7ca5-4dc6-b561-d5e6a499c90f",
        "id": "yW3KycY1IdmG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet121_Central'\n",
        "train_and_evaluate_model(Dense_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "MNrqMuY5IdmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frontal"
      ],
      "metadata": {
        "id": "zlHrbVjHI4lL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqGUjx7vI4lN"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "WhUY3GWMI4lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # x = model.output\n",
        "    # x = Flatten()(x)\n",
        "    # x = Dense(128)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "    # x = Dense(256)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "model_name = 'vgg16_Frontal'\n",
        "train_and_evaluate_model(vgg16_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "ze_XI9rzI4lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "lsCGpuxrI4lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e006f7e4-3902-4cf0-e0fc-022890729e8f",
        "id": "E4v0-p3AI4lQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'resnet50_Frontal'\n",
        "train_and_evaluate_model(resnet_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "GaGpz7_YI4lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVJBatcYI4lT"
      },
      "source": [
        "## Inception v3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "incep_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e537554f-fe57-43e7-9e15-44a8d6b25ab5",
        "id": "MkfVprAsI4lU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'InceptionV3_Frontal'\n",
        "train_and_evaluate_model(incep_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "JqTunrb4I4lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet121"
      ],
      "metadata": {
        "id": "e3ZUa3ZJI4lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dense_base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483678ff-7ca5-4dc6-b561-d5e6a499c90f",
        "id": "HUlqy5MtI4lW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet121_Frontal'\n",
        "train_and_evaluate_model(Dense_base_model, subject_folders, labels, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "mzUGIf9RI4lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concatenated"
      ],
      "metadata": {
        "id": "1yCj0gQbW5hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Final_1Hz/Final_1Hz_con/'\n",
        "\n",
        "\n",
        "def extract_numeric_part(folder_name):\n",
        "    return int(folder_name.split('_')[-1])\n",
        "\n",
        "folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))], key=extract_numeric_part)\n",
        "\n",
        "subject_folders, labels = [], []\n",
        "\n",
        "for folder_name in folders:\n",
        "    subject_num = int(folder_name.split('_')[-1])\n",
        "    subject_folder = os.path.join(data_dir, folder_name)\n",
        "    subject_folders.append(subject_folder)\n",
        "\n",
        "    if subject_num <= 36:\n",
        "        labels.append(0)  # AD group\n",
        "    elif 37 <= subject_num <= 65:\n",
        "        labels.append(1)  # HC group\n",
        "\n",
        "subject_folders = np.array(subject_folders)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "rQrESF4eXIYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(subjects, labels):\n",
        "    images, labels_t = [], []\n",
        "    for subject_folder, label in zip(subjects, labels):\n",
        "        for filename in os.listdir(subject_folder):\n",
        "                img_path = os.path.join(subject_folder, filename.decode())\n",
        "                try:\n",
        "                    img = load_img(img_path, target_size=(224, 224))\n",
        "                    img_array = img_to_array(img)\n",
        "                    img_array = img_array / 255.0\n",
        "                    images.append(img_array)\n",
        "                    labels_t.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image: {img_path}, {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels_t)"
      ],
      "metadata": {
        "id": "Y9VBD0rzi2rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(subject_folders, labels):\n",
        "    train_subjects, test_subjects, train_labels, test_labels = train_test_split(subject_folders, labels, test_size=0.2, stratify=labels)\n",
        "\n",
        "    train_subjects, val_subjects, train_labels, val_labels = train_test_split(train_subjects, train_labels, test_size=0.1, stratify=train_labels)\n",
        "\n",
        "    train_images, train_labels_t = load_images_and_labels(train_subjects, train_labels)\n",
        "    val_images, val_labels_t = load_images_and_labels(val_subjects, val_labels)\n",
        "\n",
        "    test_image_counts_per_subject = [len(os.listdir(folder)) for folder in test_subjects]\n",
        "\n",
        "    test_images, test_labels_t = load_images_and_labels(test_subjects, test_labels)\n",
        "\n",
        "    return train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject\n"
      ],
      "metadata": {
        "id": "_6aLbcdRXIYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_model(base_model):\n",
        "    model = clone_model(base_model)\n",
        "\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=predictions)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "bHfLZf3GXIYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCheckpoint(ModelCheckpoint):\n",
        "    def __init__(self, start_epoch, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.start_epoch = start_epoch\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch >= self.start_epoch:\n",
        "            super().on_epoch_end(epoch, logs)\n",
        "\n",
        "# Define a learning rate scheduler function\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch > 0 and epoch % 10 == 0:\n",
        "        return lr * (1/3)\n",
        "    return lr\n",
        "\n",
        "def train_and_evaluate_model(base_model, num_epochs=50, num_iterations=5, model_name='model'):\n",
        "    accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        print(f\"\\nIteration {iteration + 1}:\")\n",
        "\n",
        "        model = create_new_model(base_model)\n",
        "\n",
        "        train_images, train_labels_t, val_images, val_labels_t, test_images, test_labels_t, test_subjects, test_image_counts_per_subject = load_and_preprocess_data(subject_folders, labels)\n",
        "\n",
        "        train_data = list(zip(train_images, train_labels_t))\n",
        "        np.random.shuffle(train_data)\n",
        "        train_images, train_labels_t = zip(*train_data)\n",
        "\n",
        "        val_data = list(zip(val_images, val_labels_t))\n",
        "        np.random.shuffle(val_data)\n",
        "        val_images, val_labels_t = zip(*val_data)\n",
        "\n",
        "        train_images, train_labels_t = np.array(train_images), np.array(train_labels_t)\n",
        "        val_images, val_labels_t = np.array(val_images), np.array(val_labels_t)\n",
        "\n",
        "        checkpoint_dir = '/content'\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        local_checkpoint_filepath = os.path.join(checkpoint_dir, f\"{model_name}_best_weights_iteration_{iteration + 1}.h5\")\n",
        "        drive_checkpoint_filepath = f'/content/drive/My Drive/{model_name}_best_weights_iteration_{iteration + 1}.h5'\n",
        "\n",
        "        checkpoint_callback = CustomCheckpoint(\n",
        "            start_epoch=30,\n",
        "            filepath=local_checkpoint_filepath,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        class LearningRateLogger(Callback):\n",
        "            def on_epoch_end(self, epoch, logs=None):\n",
        "                logs = logs or {}\n",
        "                logs['learning_rate'] = self.model.optimizer.learning_rate.numpy()\n",
        "        lr_logger = LearningRateLogger()\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', baseline=None, restore_best_weights=False, start_from_epoch=30)\n",
        "\n",
        "        # Add the learning rate scheduler callback\n",
        "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "        history = model.fit(train_images, train_labels_t, epochs=num_epochs, batch_size=128, validation_data=(val_images, val_labels_t), callbacks=[checkpoint_callback, early_stopping, lr_scheduler], verbose=1)\n",
        "\n",
        "        if os.path.exists(local_checkpoint_filepath):\n",
        "            print(f\"Best weights saved locally at: {local_checkpoint_filepath}\")\n",
        "\n",
        "            shutil.copy(local_checkpoint_filepath, drive_checkpoint_filepath)\n",
        "            if os.path.exists(drive_checkpoint_filepath):\n",
        "                print(f\"Best weights also copied to Google Drive at: {drive_checkpoint_filepath}\")\n",
        "            else:\n",
        "                print(f\"Failed to copy best weights to Google Drive at: {drive_checkpoint_filepath}\")\n",
        "        else:\n",
        "            print(f\"Failed to save best weights locally at: {local_checkpoint_filepath}\")\n",
        "\n",
        "        model.load_weights(local_checkpoint_filepath)\n",
        "\n",
        "        test_predictions = model.predict(test_images)\n",
        "        test_predictions = (test_predictions > 0.5).astype(int)\n",
        "\n",
        "        accuracy = accuracy_score(test_labels_t, test_predictions)\n",
        "        precision = precision_score(test_labels_t, test_predictions)\n",
        "        recall = recall_score(test_labels_t, test_predictions)\n",
        "        f1 = f1_score(test_labels_t, test_predictions)\n",
        "\n",
        "        accuracy_list.append(accuracy)\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "\n",
        "        print(\"ModelCheckpoint callback triggered and saved the best weights.\")\n",
        "\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Model accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        file_name = f'{model_name}_accuracy_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        file_name = f'{model_name}_loss_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        cm = confusion_matrix(test_labels_t, test_predictions)\n",
        "        plt.figure(figsize=(6, 5))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=['AD', 'HC'], yticklabels=['AD', 'HC'])\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title(f'Confusion Matrix - {model_name} - Iteration {iteration + 1}')\n",
        "        file_name = f'{model_name}_confusion_matrix_iteration_{iteration + 1}.png'\n",
        "        plt.savefig(file_name)\n",
        "        plt.close()\n",
        "        files.download(file_name)\n",
        "\n",
        "        print(\"\\nPredictions for Each Subject's Images:\")\n",
        "        start_idx = 0\n",
        "        for i, (subject_folder, num_images) in enumerate(zip(test_subjects, test_image_counts_per_subject)):\n",
        "            end_idx = start_idx + num_images\n",
        "            subject_images = test_images[start_idx:end_idx]\n",
        "            subject_predictions = (model.predict(subject_images) > 0.5).astype(int)\n",
        "            ad_count = sum(subject_predictions == 0)\n",
        "            hc_count = sum(subject_predictions == 1)\n",
        "            print(f\"Subject {i + 1} ({subject_folder}):\")\n",
        "            print(f\"AD count: {ad_count}, HC count: {hc_count}\")\n",
        "            start_idx = end_idx\n",
        "\n",
        "    print(\"\\nAverage Metrics:\")\n",
        "    print(f\"Average Accuracy: {np.mean(accuracy_list):.4f}\")\n",
        "    print(f\"Average Precision: {np.mean(precision_list):.4f}\")\n",
        "    print(f\"Average Recall: {np.mean(recall_list):.4f}\")\n",
        "    print(f\"Average F1 Score: {np.mean(f1_list):.4f}\")\n"
      ],
      "metadata": {
        "id": "LR_7cit9XIYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNUZDQaYXIYp"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QTPYOLlXIYq",
        "outputId": "b7bc6600-572c-4aae-ffba-2805c1832a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # x = model.output\n",
        "    # x = Flatten()(x)\n",
        "    # x = Dense(128)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "    # x = Dense(256)(x)\n",
        "    # x = Dropout(0.2)(x)\n",
        "model_name = 'vgg16_con'\n",
        "train_and_evaluate_model(vgg16_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "1ZLFxnar3mb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'vgg16_con_2'\n",
        "train_and_evaluate_model(vgg16_base_model, num_epochs=100, num_iterations=1, model_name=model_name)"
      ],
      "metadata": {
        "id": "PbvFDkerA8Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "SJaUkQ1axgG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09ab0b7-c7db-41e0-8bb1-b0792cfe5125",
        "id": "SVPfI91Txi86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ResNet50_con'\n",
        "train_and_evaluate_model(ResNet50_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "g5BsE474xi9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## InceptionV3"
      ],
      "metadata": {
        "id": "gbJlU7YrAUmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Incep_base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c775cf-9984-4c69-b6f4-153c39c0047c",
        "id": "a3ZLoPSOAUmu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'InceptionV3_con'\n",
        "train_and_evaluate_model(Incep_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "QXIWlN2UAUmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet121"
      ],
      "metadata": {
        "id": "xIUyTCy_JXdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet121_con'\n",
        "train_and_evaluate_model(resnet_base_model, num_epochs=100, num_iterations=5, model_name=model_name)"
      ],
      "metadata": {
        "id": "OOdIPxBfJWwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}